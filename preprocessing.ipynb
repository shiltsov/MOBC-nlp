{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f718c4f8",
   "metadata": {},
   "source": [
    "# Игры с предобработкой текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4c39d",
   "metadata": {},
   "source": [
    "### Хочу поиграть с разбивкой \n",
    "\n",
    "не только на слова но и на 2- 3-х буквенные сочетания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce3e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'м': 9,\n",
       " 'а': 1,\n",
       " ' ': 0,\n",
       " 'ч': 16,\n",
       " 'с': 13,\n",
       " 'т': 14,\n",
       " 'о': 11,\n",
       " 'ы': 17,\n",
       " 'л': 8,\n",
       " 'р': 12,\n",
       " 'у': 15,\n",
       " 'н': 10,\n",
       " 'и': 6,\n",
       " 'е': 5,\n",
       " 'в': 2,\n",
       " 'г': 3,\n",
       " 'д': 4,\n",
       " 'к': 7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize, ToktokTokenizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "text  = [\"мама часто мыла раму но и не всегда качественно\"]\n",
    "cv = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "bow = cv.fit_transform(text)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e22745c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мама', 'часто', 'мыла', 'раму', 'но', 'и', 'не', 'всегда', 'качественно']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text  = \"мама часто мыла раму но и не всегда качественно\"\n",
    "wt = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d505573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sda/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'мама': 4,\n",
       " 'часто': 9,\n",
       " 'мыла': 5,\n",
       " 'раму': 8,\n",
       " 'но': 7,\n",
       " 'и': 2,\n",
       " 'не': 6,\n",
       " 'все-': 0,\n",
       " 'гда': 1,\n",
       " 'качественно': 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text  = [\"мама часто мыла раму но и не все-\\nгда качественно\"]\n",
    "cv = CountVectorizer(tokenizer=word_tokenize)\n",
    "bow = cv.fit_transform(text)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b378f1",
   "metadata": {},
   "source": [
    "### Разбивка слова на слоги\n",
    "\n",
    "https://vc.ru/newtechaudit/309131-obzor-tokenizatorov-vhodyashchih-v-sostav-biblioteki-nltk?ysclid=lolzc1qfra229952282\n",
    "\n",
    "LegalitySyllableTokenizer<br>\n",
    "нужно загрузить русские гласные и словарь<br><br>\n",
    "Принцип правильности (Legality Principle) – это не зависящий от используемого языка принцип, утверждающий, что начала и окончания слогов (не включая гласный звук) допустимы только в том случае, если они встречаются в качестве начал или окончаний слов в языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77b49955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141267\n"
     ]
    }
   ],
   "source": [
    "# загрузка словаря русских слов\n",
    "with open('./rus-dict/dict.opcorpora.txt', 'r', encoding='utf-8') as f:\n",
    "    all_line = f.readlines()\n",
    "clear_words = [line.split('\\t')[0].lower() for line in all_line if len(line.split('\\t')) > 1]\n",
    "print(len(clear_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90835bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['при', 'ши', 'бен', 'но'], ['у', 'кла', 'ды', 'вать'], ['ско', 'ро', 'го', 'вор', 'ка']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import LegalitySyllableTokenizer\n",
    "\n",
    "tok = LegalitySyllableTokenizer(clear_words, vowels='аеёиоуыэюя')\n",
    "text_words = [\"пришибенно\", \"укладывать\",\"скороговорка\"]\n",
    "print([tok.tokenize(word) for word in text_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a892ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070130b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55fed60a",
   "metadata": {},
   "source": [
    "### Разбивка на предложения (аккуратная)\n",
    "\n",
    "PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe03daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Липецкая область вошла в число лидеров... в исполнении поручения Президента России.', 'А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь']\n"
     ]
    }
   ],
   "source": [
    "text = 'Липецкая область вошла в число лидеров... в исполнении поручения Президента России. А Рязанская область подписала соглашение о развитии сотрудничества с Республикой Беларусь'\n",
    "tok = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "print(len(tok.tokenize(text)))\n",
    "print(tok.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a74dac",
   "metadata": {},
   "source": [
    "### Есть идея использовать статистику по частям речи и по падежам используемых существительных\n",
    "\n",
    "как выдрать падеж из слова - mystem (лемматизация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3335627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fe3b394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мама', ' ', 'часто', ' ', 'мыть', ' ', 'рама', ' ', 'но', ' ', 'и', ' ', 'не', ' ', 'всегда', ' ', 'качественно', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "example = \"маме часто мыла раму но и не всегда качественно.\"\n",
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "480282a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'пирожок', 'wt': 1, 'gr': 'S,муж,неод=твор,мн'}],\n",
       "  'text': 'пирожками'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(\"пирожками\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1de666f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'распиливаться',\n",
       "    'wt': 1,\n",
       "    'qual': 'bastard',\n",
       "    'gr': 'V,нп=непрош,мн,изъяв,3-л,сов'}],\n",
       "  'text': 'распилятся'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(\"распилятся\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fc66095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'наш', 'wt': 1, 'gr': 'APRO=(дат,ед,муж|дат,ед,сред)'}],\n",
       "  'text': 'нашему'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(\"нашему\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a75a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
